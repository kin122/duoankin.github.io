### term查询
Term 是表达语意的最⼩单位。搜索和利⽤统计语⾔模型进⾏⾃然语⾔处理都需要处理 Term。  
https://lucene.apache.org/core/8_9_0/core/org/apache/lucene/index/Term.html  
在 ES 中，Term 查询，对输⼊不做分词。会将输⼊作为⼀个整体，在倒排索引中查找准确的词项，并且使⽤相关度算分公式为每个包含该词项的⽂档进⾏相关度算分。  
term 查询在 text 文档中的实现l1精确查询，需要 term 与文档完全对应。  
实现案例  
```
PUT my-index-000001
{
  "mappings": {
    "properties": {
      "full_text": { "type": "text" }
    }
  }
}
PUT my-index-000001/_doc/1
{
  "full_text":   "Quick Brown Foxes!"
}
GET my-index-000001/_search?pretty
{
  "query": {
    "term": {
      "full_text": "Quick Brown Foxes!"
    }
  }
}
GET my-index-000001/_search?pretty
{
  "query": {
    "match": {
      "full_text": "Quick Brown Foxes!"
    }
  }
}
```
### match查询
索引和搜索时都会进⾏分词，查询字符串先传递到⼀个合适的分词器，然后⽣成⼀个供查询的词项列表  
查询时候，先会对输⼊的查询进⾏分词，然后每个词项逐个进⾏底层的查询，最终将结果进⾏合并。并为每个⽂档⽣成⼀个算分。  
查询主要参数：
**Operator**  
**minimum_should_match**  
### 原理与实践
#### term token fields之间的联系
https://www.zhihu.com/question/32133683  
https://lucene.apache.org/core/8_9_0/core/index.html
Plain text passed to Lucene for indexing goes through a process generally called tokenization. Tokenization is the process of breaking input text into small indexing elements – tokens. The way input text is broken into tokens heavily influences how people will then be able to search for that text. For instance, sentences beginnings and endings can be identified to provide for more accurate phrase and proximity searches (though sentence identification is not provided by Lucene).   
https://lucene.apache.org/core/8_9_0/core/index.html  
A field that is indexed and tokenized, without term vectors. For example this would be used on a 'body' field, that contains the bulk of a document's text.

#### match不匹配情况  


### 精确搜索的相关方法
#### term
参数  
可以通过 Constant Score 将查询转换成⼀个 Filtering，避免算分，并利⽤缓存，提⾼性能  

#### terms
#### terms_set
#### wildcard
#### range
#### fuzzy
#### prefix
#### regexp
#### type
#### ids
#### exists
### 全文搜索的相关方法
#### match
#### match_phrase
#### match_phrase_prefix
#### multi_match
#### match_bool_prefix
#### query_string
#### simple_query_string
#### intervals
#### common terms
### lucene中的精确搜索和全文匹配
#### lucene的查询基本类
#### lucene的queryparser

